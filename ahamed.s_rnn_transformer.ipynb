{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2a6e9e8b",
      "metadata": {
        "id": "2a6e9e8b"
      },
      "source": [
        "# Programming assignment 2: Recurrent Neural Networks and Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f7493e6",
      "metadata": {
        "id": "7f7493e6"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "193d314b",
      "metadata": {
        "id": "193d314b"
      },
      "source": [
        "<font size='4'>In this assignment you will practice putting together implementations of Recurrent Neural Networks, Transformer (encoder and decoder), and their applications to text classification, image classification, and text generation (machine translation). Especially for Transformer, you will get good understandings about foundations for very state-of-the-art models that you likely to see in tech news articles nowadays, like GPT-3, CLIP, or VisionTransformer.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e938397f",
      "metadata": {
        "id": "e938397f"
      },
      "source": [
        "## Submission format"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e960af27",
      "metadata": {
        "id": "e960af27"
      },
      "source": [
        "- <font size='4'>`<your_nu_username>_rnn_transformer.ipynb` with your implementations and output.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3460ded9",
      "metadata": {
        "id": "3460ded9"
      },
      "source": [
        "## Note"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "549c3563",
      "metadata": {
        "id": "549c3563"
      },
      "source": [
        "<font size='4'>  \n",
        "- You do not need to tune hyper parameters in the regular tasks.\n",
        "\n",
        "- You do not install any additional packages inside the Colab environment. Do not forget to choose to use GPU in the `Runtime\\Change runtime type` tab.    \n",
        "\n",
        "- **You are not allowed to consult any online resources except for the links provided in this assignment.**\n",
        "\n",
        "- **Violation of this policy will lead to failure of your course and even more severe consequences.**\n",
        "\n",
        "- Attend office hours and make post on Piazza if you have any questions.\n",
        "\n",
        "- You have sufficient time to work on this assignment. Please refrain from asking for extensions.\n",
        "\n",
        "- The thrid programming assignment is optional but you may earn extra credits out it. Plan wisely as its deadline may approach the end of this semester, where there are a lot of deadlines around.\n",
        "</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c34a5320",
      "metadata": {
        "id": "c34a5320"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3e59bfb8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e59bfb8",
        "outputId": "255c2cd0-df39-4fe0-98dc-3d0ff0bd8168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.6.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "2023-04-11 04:42:04.283500: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-11 04:42:05.262346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-11 04:42:06.573021: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-11 04:42:06.573513: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-11 04:42:06.573686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-04-11 04:42:21.931320: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-11 04:42:22.960340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-11 04:42:24.271826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-11 04:42:24.272282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-11 04:42:24.272476: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting de-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.5.0/de_core_news_sm-3.5.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from de-core-news-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->de-core-news-sm==3.5.0) (2.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "Found existing installation: torch 2.0.0+cu118\n",
            "Uninstalling torch-2.0.0+cu118:\n",
            "  Successfully uninstalled torch-2.0.0+cu118\n",
            "Found existing installation: torchdata 0.6.0\n",
            "Uninstalling torchdata-0.6.0:\n",
            "  Successfully uninstalled torchdata-0.6.0\n",
            "Found existing installation: torchvision 0.15.1+cu118\n",
            "Uninstalling torchvision-0.15.1+cu118:\n",
            "  Successfully uninstalled torchvision-0.15.1+cu118\n",
            "Found existing installation: torchtext 0.15.1\n",
            "Uninstalling torchtext-0.15.1:\n",
            "  Successfully uninstalled torchtext-0.15.1\n",
            "Found existing installation: torchaudio 2.0.1+cu118\n",
            "Uninstalling torchaudio-2.0.1+cu118:\n",
            "  Successfully uninstalled torchaudio-2.0.1+cu118\n",
            "Found existing installation: fastai 2.7.12\n",
            "Uninstalling fastai-2.7.12:\n",
            "  Successfully uninstalled fastai-2.7.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.1.0.dev20230410%2Bcpu-cp39-cp39-linux_x86_64.whl (196.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.6/196.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchdata\n",
            "  Downloading https://download.pytorch.org/whl/nightly/torchdata-0.7.0.dev20230410-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchdata) (2.27.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: torch, torchdata\n",
            "Successfully installed torch-2.1.0.dev20230410+cpu torchdata-0.7.0.dev20230410\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext\n",
            "  Downloading torchtext-0.15.1-cp39-cp39-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext) (2.27.1)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext) (4.65.0)\n",
            "Collecting torchdata==0.6.0\n",
            "  Downloading torchdata-0.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (2.0.0)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.10.7)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch==2.0.0->torchtext) (3.1.2)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.9/dist-packages (from torchdata==0.6.0->torchtext) (1.26.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (67.6.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext) (0.40.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext) (3.25.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch==2.0.0->torchtext) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch==2.0.0->torchtext) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchdata, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0.dev20230410+cpu\n",
            "    Uninstalling torch-2.1.0.dev20230410+cpu:\n",
            "      Successfully uninstalled torch-2.1.0.dev20230410+cpu\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.7.0.dev20230410\n",
            "    Uninstalling torchdata-0.7.0.dev20230410:\n",
            "      Successfully uninstalled torchdata-0.7.0.dev20230410\n",
            "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1\n"
          ]
        }
      ],
      "source": [
        "# ==================\n",
        "# ATTENTION:\n",
        "# For the first time, uncomment the following lines and re-run the cell.\n",
        "# You may have to hit the \"RESTART RUNTIME\" button in the output and then re-run this cell.\n",
        "# Once it is done, you can comment the following lines and run other cells.\n",
        "# ==================\n",
        "\n",
        "# # Create source and target language tokenizer. Make sure to install the dependencies.\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip uninstall -y torch torchdata torchvision torchtext torchaudio fastai\n",
        "!pip install portalocker\n",
        "!pip install --pre torch torchdata -f https://download.pytorch.org/whl/nightly/cpu/torch_nightly.html\n",
        "!pip install torchtext"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d789993e",
      "metadata": {
        "id": "d789993e"
      },
      "source": [
        "## Part 1: Text Classification with RNN (24 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "92081dc6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92081dc6",
        "outputId": "7265b282-8546-4d6c-88c2-af2bb864765a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120000\n",
            "(3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext.datasets import AG_NEWS\n",
        "train_iter = AG_NEWS(split='train')\n",
        "\n",
        "# Let's check what the data looks like\n",
        "print(len(list(train_iter)))\n",
        "print(next(iter(train_iter)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28eb6bd7",
      "metadata": {
        "id": "28eb6bd7"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.1: Implement a RNNCell (4 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2db54f12",
      "metadata": {
        "id": "2db54f12"
      },
      "outputs": [],
      "source": [
        "# Documentation of nn.Module https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module\n",
        "class RNNCell(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    RNNCell is a single cell that takes x_t and h_{t_1} as input and outputs h_t.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        Constructor of RNNCell.\n",
        "        \n",
        "        Inputs: \n",
        "        - input_dim: Dimension of the input x_t\n",
        "        - hidden_dim: Dimension of the hidden state h_{t-1} and h_t\n",
        "        \"\"\"\n",
        "        \n",
        "        # We always need to do this step to properly implement the constructor\n",
        "        super(RNNCell, self).__init__()\n",
        "        \n",
        "        self.linear_x, self.linear_h, self.non_linear = None, None, None  \n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define the linear transformation layers for x_t and h_{t-1} and   #\n",
        "        # the non-linear layer. You can use tanh here.                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        # x_t, input at current time step\n",
        "        self.linear_x = nn.Linear(input_dim, hidden_dim)\n",
        "        # h_{t-1}, input at previous time step\n",
        "        self.linear_h = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # non-linear activation, tanh\n",
        "        self.non_linear = nn.Tanh()\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, x_cur: torch.Tensor, h_prev: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute h_t given x_t and h_{t-1}.\n",
        "        \n",
        "        Inputs:\n",
        "        - x_cur: x_t, a tensor with the same of BxC, where B is the batch size and \n",
        "          C is the channel dimension.\n",
        "        - h_prev: h_{t-1}, a tensor with the same of BxH, where H is the channel\n",
        "          dimension.\n",
        "        \"\"\"\n",
        "        h_cur = None\n",
        "        ###########################################################################\n",
        "        # TODO: Define the linear transformation layers for x_t and h_{t-1} and   #\n",
        "        # the non-linear layer.                                                   #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # transform the inputs and send through activation function\n",
        "        x = self.linear_x(x_cur)\n",
        "        h = self.linear_h(h_prev)\n",
        "        h_cur = self.non_linear(x+h)\n",
        "        \n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        return h_cur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b62f7e2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b62f7e2d",
        "outputId": "f1e17b90-697f-4198-f0c4-33d7dd784d52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 16])\n"
          ]
        }
      ],
      "source": [
        "# Let's run a sanity check of your model\n",
        "x = torch.randn((2, 8))\n",
        "h = torch.randn((2, 16))\n",
        "model = RNNCell(8, 16)\n",
        "y = model(x, h)\n",
        "assert len(y.shape) == 2 and y.shape[0] == 2 and y.shape[1] == 16\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb2ee43c",
      "metadata": {
        "id": "cb2ee43c"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.2: Implement a single-layer (single-stack) RNN (5 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f0120521",
      "metadata": {
        "id": "f0120521"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    RNN is a single-layer (stack) RNN by connecting multiple RNNCell together in a single\n",
        "    direction, where the input sequence is processed from left to right.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int):\n",
        "        \"\"\"\n",
        "        Constructor of the RNN module.\n",
        "        \n",
        "        Inputs: \n",
        "        - input_dim: Dimension of the input x_t\n",
        "        - hidden_dim: Dimension of the hidden state h_{t-1} and h_t\n",
        "        \"\"\"\n",
        "        super(RNN, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define the RNNCell.                                               #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # defining the RNNCell class from earlier\n",
        "        self.RNNCell = RNNCell(input_dim, hidden_dim)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Compute the hidden representations for every token in the input sequence.\n",
        "        \n",
        "        Input:\n",
        "        - x: A tensor with the shape of BxLxC, where B is the batch size, L is the squence \n",
        "          length, and C is the channel dimmension\n",
        "          \n",
        "        Return:\n",
        "        - h: A tensor with the shape of BxLxH, where H is the hidden dimension of RNNCell\n",
        "        \"\"\"\n",
        "        b = x.shape[0]\n",
        "        seq_len = x.shape[1]\n",
        "        \n",
        "        # initialize the hidden dimension\n",
        "        init_h = x.new_zeros((b, self.hidden_dim))\n",
        "        \n",
        "        h = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the hidden representation for every token in the input    #\n",
        "        # from left to right.\n",
        "        ###########################################################################\n",
        "        \n",
        "        hState = []\n",
        "\n",
        "        for timestep in range(seq_len):\n",
        "          # current input element\n",
        "          tInput = x[:, timestep, :]\n",
        "          # compute current hidden state\n",
        "          if timestep == 0:\n",
        "            cHidden = self.RNNCell(tInput, init_h)\n",
        "          else:\n",
        "            cHidden = self.RNNCell(tInput, pHidden)\n",
        "          # store hidden state\n",
        "          hState.append(cHidden)\n",
        "          # update previous hidden state\n",
        "          pHidden = cHidden\n",
        "          \n",
        "        # stack hidden states along the sequence(1) dimension\n",
        "        h = torch.stack(hState, dim=1)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return h\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dfb661d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfb661d8",
        "outputId": "285c4463-c8ab-4ae5-aff2-0d4945c49390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 16])\n"
          ]
        }
      ],
      "source": [
        "# Let's run a sanity check of your model\n",
        "x = torch.randn((2, 10, 8))\n",
        "model = RNN(8, 16)\n",
        "y = model(x)\n",
        "assert len(y.shape) == 3\n",
        "for dim, dim_gt in zip(y.shape, [2, 10, 16]):\n",
        "    assert dim == dim_gt\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90f8ec47",
      "metadata": {
        "id": "90f8ec47"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.3: Implement a RNN-based text classifier (4 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ed42889c",
      "metadata": {
        "id": "ed42889c"
      },
      "outputs": [],
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A RNN-based classifier for text classification. It first converts tokens into word embeddings.\n",
        "    And then feeds the embeddings into a RNN, where the hidden representations of all tokens are\n",
        "    then averaged to get a single embedding of the sentence. It will be used as input to a linear\n",
        "    classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "            vocab_size: int, embed_dim: int, rnn_hidden_dim: int, num_class: int, pad_token: int\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        \n",
        "        Inputs:\n",
        "        - vocab_size: Vocabulary size, indicating how many tokens we have in total.\n",
        "        - embed_dim: The dimension of word embeddings\n",
        "        - rnn_hidden_dim: The hidden dimension of the RNN.\n",
        "        - num_class: Number of classes.\n",
        "        - pad_token: The index of the padding token.\n",
        "        \"\"\"\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        \n",
        "        # word embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_token)\n",
        "        \n",
        "        self.rnn, self.fc = None, None\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define the RNN and the classification layer.                      #\n",
        "        ###########################################################################\n",
        "        \n",
        "        self.RNN = RNN(embed_dim, rnn_hidden_dim)\n",
        "        # linear classifier\n",
        "        self.lin = nn.Linear(rnn_hidden_dim, num_class)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text):\n",
        "        \"\"\"\n",
        "        Get classification scores (logits) of the input.\n",
        "        \n",
        "        Input:\n",
        "        - text: Tensor with the shape of BxLxC.\n",
        "        \n",
        "        Return:\n",
        "        - logits: Tensor with the shape of BxK, where K is the number of classes\n",
        "        \"\"\"\n",
        "        \n",
        "        # get word embeddings\n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute logits of the input.                                      #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # send word embeddings through RNN\n",
        "        RNNoutput = self.RNN(embedded)\n",
        "        # average along hidden dim(1)\n",
        "        AVGoutput = torch.mean(RNNoutput, dim=1)\n",
        "        # get logitcs through fc\n",
        "        logits = self.lin(AVGoutput)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ce2d2044",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce2d2044",
        "outputId": "282bcc15-2820-4368-9fae-324c3678c654"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x.shape: torch.Size([2, 10])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 3]) cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Let's run a sanity check of your model\n",
        "vocab_size = 10\n",
        "embed_dim = 16\n",
        "rnn_hidden_dim = 32\n",
        "num_class = 3\n",
        "\n",
        "x = torch.arange(vocab_size).view(1, -1)\n",
        "x = torch.cat((x, x), dim=0)\n",
        "print('x.shape: {}'.format(x.shape))\n",
        "model = RNNClassifier(vocab_size, embed_dim, rnn_hidden_dim, num_class, 0)\n",
        "y = model(x)\n",
        "assert len(y.shape) == 2 and y.shape[0] == 2 and y.shape[1] == num_class\n",
        "print(y.shape)\n",
        "\n",
        "model = model.to('cuda:0')\n",
        "x = x.to('cuda:0')\n",
        "y = model(x)\n",
        "print(y.shape, y.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "612890ad",
      "metadata": {
        "id": "612890ad"
      },
      "source": [
        "### Set up data related stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c92ea24e",
      "metadata": {
        "id": "c92ea24e"
      },
      "outputs": [],
      "source": [
        "# check here for details https://github.com/pytorch/text/blob/main/torchtext/data/utils.py#L52-#L166\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "# check here for details https://github.com/pytorch/text/blob/main/torchtext/vocab/vocab_factory.py#L65-L113\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# A tokenizer splits a input setence into a set of tokens, including those puncuation\n",
        "# For example\n",
        "# >>> tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
        "# >>> tokens\n",
        "# >>> ['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "# Creates a vocab object which maps tokens to indices\n",
        "# Check here for details https://github.com/pytorch/text/blob/main/torchtext/vocab/vocab.py\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "\n",
        "# The specified token will be returned when a out-of-vocabulary token is queried.\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1\n",
        "\n",
        "# The padding token we need to use\n",
        "# The returned indices are always in an array\n",
        "PAD_TOKEN = vocab(tokenizer('<pad>'))\n",
        "assert len(PAD_TOKEN) == 1\n",
        "PAD_TOKEN = PAD_TOKEN[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f13c252",
      "metadata": {
        "id": "0f13c252"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.4: Collate Batched Data with Data Loaders (4 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bdd006c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdd006c5",
        "outputId": "18e92f84-2a4c-4f55-9284-0b329ba12c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label.shape: torch.Size([8])\n",
            "label: tensor([2, 2, 2, 2, 2, 2, 2, 2])\n",
            "data.shape: torch.Size([8, 49])\n"
          ]
        }
      ],
      "source": [
        "# Documentation of DataLoader https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "from torch.utils.data import DataLoader  \n",
        "\n",
        "# Merges a list of samples to form a mini-batch of Tensor(s)\n",
        "def collate_batch(batch):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "    - batch: A list of data in a mini batch, where the length denotes the batch size. \n",
        "      The actual context depends on a particular dataset. In our case, each position \n",
        "      contains a label and a Tensor (tokens in a sentence).\n",
        "      \n",
        "    Returns:\n",
        "    - batched_label: A Tensor with the shape of (B,)\n",
        "    - batched_text: A Tensor with the shape of (B, L, C), where L is the sequence length\n",
        "      and C is the channeld dimension\n",
        "    \"\"\"\n",
        "    label_list, text_list, text_len_list = [], [], []\n",
        "    for (_label, _text) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        text_len_list.append(processed_text.size(0))\n",
        "    batched_label, batched_text = [], []\n",
        "    # print(label_list)\n",
        "    # print(text_list)\n",
        "    # print(text_len_list)\n",
        "    ###########################################################################\n",
        "    # TODO: Pad the text tensor in the mini batch so that they have the same  #\n",
        "    # length. Specifically, you need to calculate the maximum length in the   #\n",
        "    # batch and then add the token PAD_TOKEN to the end of those              #\n",
        "    # shorter sentences.                                                      #\n",
        "    ###########################################################################\n",
        "    \n",
        "    # get max sentence length in the batch\n",
        "    maxBatch = max(text_len_list)\n",
        "    for sentenceNum in range(len(text_list)):\n",
        "      # if the length is shorter than max, find difference and pad\n",
        "      if text_len_list[sentenceNum] < maxBatch:\n",
        "        difference = maxBatch - text_len_list[sentenceNum]\n",
        "        batched_text.append(torch.cat([text_list[sentenceNum], torch.tensor([PAD_TOKEN] * difference)]))\n",
        "      else:\n",
        "        batched_text.append(text_list[sentenceNum])\n",
        "      batched_label.append(label_list[sentenceNum])\n",
        "\n",
        "    # convert to tensors \n",
        "    batched_label = torch.tensor(batched_label)\n",
        "    batched_text = torch.stack(batched_text)\n",
        "    \n",
        "    ###########################################################################\n",
        "    #                             END OF YOUR CODE                            #\n",
        "    ###########################################################################\n",
        "    \n",
        "    return batched_label.long(), batched_text.long()\n",
        "\n",
        "# Now, let's check what the batched data looks like\n",
        "train_iter = AG_NEWS(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "for idx, (label, data) in enumerate(dataloader):\n",
        "    if idx > 0:\n",
        "        break\n",
        "    print('label.shape: {}'.format(label.shape))\n",
        "    print('label: {}'.format(label))\n",
        "    print('data.shape: {}'.format(data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5c3571e",
      "metadata": {
        "id": "a5c3571e"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.5: Functions of training for a single epoch and evaluation (4 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b5dc8d4a",
      "metadata": {
        "id": "b5dc8d4a"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(model, dataloader, loss_func, device, grad_norm_clip):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text) in enumerate(dataloader):\n",
        "        label = label.to(device)\n",
        "        text = text.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: compute the logits of the input, get the loss, and do the         #\n",
        "        # gradient backpropagation.\n",
        "        ###########################################################################\n",
        "\n",
        "        # get logits from the model\n",
        "        logits = model(text)\n",
        "        # get the loss\n",
        "        loss = loss_func(logits, label)\n",
        "        # back prop\n",
        "        loss.backward()\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
        "        optimizer.step()\n",
        "        total_acc += (logits.argmax(1) == label).sum().item()  \n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model, dataloader, loss_func, device):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text) in enumerate(dataloader):\n",
        "            label = label.to(device)\n",
        "            text = text.to(device)\n",
        "            \n",
        "            ###########################################################################\n",
        "            # TODO: compute the logits of the input, get the loss.                    #\n",
        "            ###########################################################################\n",
        "\n",
        "            # get logits from the model\n",
        "            logits = model(text)\n",
        "            # get the loss\n",
        "            loss = loss_func(logits, label)\n",
        "            \n",
        "            ###########################################################################\n",
        "            #                             END OF YOUR CODE                            #\n",
        "            ###########################################################################\n",
        "            \n",
        "            total_acc += (logits.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e249cd2c",
      "metadata": {
        "id": "e249cd2c"
      },
      "source": [
        "### <font size='4' color='red'>Task 1.6: Define the model and loss function to train the model (3 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0112151f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0112151f",
        "outputId": "0520df7f-710b-44d5-da28-3e1c1b95c025"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 1782 batches | accuracy    0.500\n",
            "| epoch   1 |  1000/ 1782 batches | accuracy    0.725\n",
            "| epoch   1 |  1500/ 1782 batches | accuracy    0.789\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 84.19s | valid accuracy    0.826 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1782 batches | accuracy    0.844\n",
            "| epoch   2 |  1000/ 1782 batches | accuracy    0.856\n",
            "| epoch   2 |  1500/ 1782 batches | accuracy    0.868\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 83.86s | valid accuracy    0.873 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1782 batches | accuracy    0.886\n",
            "| epoch   3 |  1000/ 1782 batches | accuracy    0.888\n",
            "| epoch   3 |  1500/ 1782 batches | accuracy    0.895\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 81.85s | valid accuracy    0.886 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "assert torch.cuda.is_available()\n",
        "# device = 'cuda'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyper parameters\n",
        "epochs = 3 # epoch\n",
        "lr = 0.0005 # learning rate\n",
        "batch_size = 64 # batch size for training\n",
        "word_embed_dim = 64\n",
        "rnn_hidden_dim = 96\n",
        "\n",
        "train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "model, loss_func = None, None\n",
        "###########################################################################\n",
        "# TODO: Deinfe the classifier and loss function.\n",
        "###########################################################################\n",
        "\n",
        "model = RNNClassifier(vocab_size, word_embed_dim, rnn_hidden_dim, num_class, PAD_TOKEN)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "\n",
        "# copy the model to the specified device (GPU)\n",
        "model = model.to(device)\n",
        "        \n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 1e-8)\n",
        "total_accu = None\n",
        "train_iter, test_iter = AG_NEWS()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = random_split(\n",
        "    train_dataset, \n",
        "    [num_train, len(train_dataset) - num_train]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    split_train_, batch_size=batch_size,\n",
        "    shuffle=True, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "valid_dataloader = DataLoader(\n",
        "    split_valid_, batch_size=batch_size, \n",
        "    shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=batch_size,\n",
        "    shuffle=False, collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "# You should be able get a validation accuracy around 87%\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, train_dataloader, loss_func, device, 1)\n",
        "    accu_val = evaluate(model, valid_dataloader, loss_func, device)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3582578",
      "metadata": {
        "id": "e3582578"
      },
      "source": [
        "## Part 2: Text Classification with Transformer Encoder (41 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4db1190d",
      "metadata": {
        "id": "4db1190d"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.1: Implement the multi-head attention module (no for loops allowed, 10 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7d932295",
      "metadata": {
        "id": "7d932295"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A module that computes multi-head attention given query, key, and value tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int):\n",
        "        \"\"\"\n",
        "        Constructor.\n",
        "        \n",
        "        Inputs:\n",
        "        - input_dim: Dimension of the input query, key, and value. Here we assume they all have\n",
        "          the same dimensions. But they could have different dimensions in other problems.\n",
        "        - num_heads: Number of attention heads\n",
        "        \"\"\"\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        \n",
        "        assert input_dim % num_heads == 0\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dim_per_head = input_dim // num_heads\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define the linear transformation layers for key, value, and query.#\n",
        "        # Also define the output layer.\n",
        "        ###########################################################################\n",
        "\n",
        "        # send all the copied matrices into a fc layer, since linear output dimension is not mentioned we use input_dim itself as output(based on piazza @176)\n",
        "        self.QueryLinear = nn.Linear(input_dim, input_dim)\n",
        "        self.KeyLinear = nn.Linear(input_dim, input_dim)\n",
        "        self.ValueLinear = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        # output Linear\n",
        "        self.outputLinear = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        \n",
        "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor=None):\n",
        "        \"\"\"\n",
        "        Compute the attended feature representations.\n",
        "        \n",
        "        Inputs:\n",
        "        - query: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - key: Tensor of the shape BxLxC\n",
        "        - value: Tensor of the shape BxLxC\n",
        "        - mask: Tensor indicating where the attention should *not* be performed\n",
        "        \"\"\"\n",
        "        b = query.shape[0]        \n",
        "        \n",
        "        dot_prod_scores = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the scores based on dot product between transformed query,#\n",
        "        # key, and value. You may find torch.matmul helpful, whose documentation  #\n",
        "        # can be found at                                                         #\n",
        "        # https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul#\n",
        "        # Remember to devide the doct product similarity scores by square root of #\n",
        "        # the channel dimension per head.   \n",
        "        #                                                                         #\n",
        "        # Since no for loops are allowed here, think of how to use tensor reshape #\n",
        "        # to process multiple attention heads at the same time.                   #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # send the 3 tensors through linear layer\n",
        "        QueryL = self.QueryLinear(query)\n",
        "        KeyL = self.KeyLinear(key)\n",
        "        ValueL = self.ValueLinear(value)\n",
        "\n",
        "        # single head logic\n",
        "        # # matmul b/n Query and Key (Q.K(transpose))\n",
        "        # MatMul_QK = torch.matmul(QueryL, KeyL.transpose(-1,-2))\n",
        "        # # scale b/n Query and Key, divide by square root of dim per head\n",
        "        # Scale_QK = MatMul_QK / math.sqrt(self.dim_per_head)\n",
        "        # # dot product scores\n",
        "        # dot_prod_scores = Scale_QK\n",
        "\n",
        "        # convert into a single multiheaded vector\n",
        "        MultiQueryL = QueryL.reshape(b, -1, self.num_heads, self.dim_per_head).transpose(1,2)\n",
        "        MultiKeyL = KeyL.reshape(b, -1, self.num_heads, self.dim_per_head).transpose(1,2)\n",
        "        MultiValueL = ValueL.reshape(b, -1, self.num_heads, self.dim_per_head).transpose(1,2)\n",
        "\n",
        "        # matmul(Q.K^T) and scaling(div by root Key dim)\n",
        "        MatMul_QK = torch.matmul(MultiQueryL, MultiKeyL.transpose(-1,-2))\n",
        "        dot_prod_scores = MatMul_QK / math.sqrt(self.dim_per_head)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        if mask is not None:\n",
        "            # We simply set the similarity scores to be near zero for the positions\n",
        "            # where the attention should not be done. Think of why we do this.\n",
        "            dot_prod_scores = dot_prod_scores.masked_fill(mask == 0, -1e9)\n",
        "        \n",
        "        out = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the attention scores, which are then used to modulate the #\n",
        "        # value tensor. Finally concate the attended tensors from multiple heads  #\n",
        "        # and feed it into the output layer. You may still find torch.matmul      #\n",
        "        # helpful.                                                                #\n",
        "        #                                                                         #\n",
        "        # Again, think of how to use reshaping tensor to do the concatenation.    #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # softmax to normalize\n",
        "        attentionScore = F.softmax(dot_prod_scores, dim=-1)\n",
        "        # matmul b/n attention score and value linear\n",
        "        valueTensor = torch.matmul(attentionScore, MultiValueL)\n",
        "        # concatenate, step 1: transpose dim 1,2 to their original order\n",
        "        valueTensor = valueTensor.transpose(1,2)\n",
        "        # concatenate, step 2: merge last 2 dims\n",
        "        valueTensor = valueTensor.contiguous().view(b, -1, self.input_dim)\n",
        "        # send to fc\n",
        "        out = self.outputLinear(valueTensor)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c5bd2c45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5bd2c45",
        "outputId": "99c0ccc5-2a29-4a09-a24e-5f0086b5ad59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 8])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "mask = torch.randn((2, 10)) > 0.5\n",
        "mask = mask.unsqueeze(1).unsqueeze(-1)\n",
        "num_heads = 4\n",
        "model = MultiHeadAttention(8, num_heads)\n",
        "y = model(x, x, x, mask)\n",
        "assert len(y.shape) == len(x.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02379104",
      "metadata": {
        "id": "02379104"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.2: Implement a Feedforward Network (3 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "5b7083ff",
      "metadata": {
        "id": "5b7083ff"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    A simple feedforward network. Essentially, it is a two-layer fully-connected\n",
        "    neural network.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, ff_dim, dropout):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension\n",
        "        - ff_dim: Hidden dimension\n",
        "        \"\"\"\n",
        "        super(FeedForwardNetwork, self).__init__()\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define the two linear layers and a non-linear one.\n",
        "        ###########################################################################\n",
        "\n",
        "        self.Lin1 = nn.Linear(input_dim, ff_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout= nn.Dropout(dropout)\n",
        "        self.Lin2 = nn.Linear(ff_dim, input_dim)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "         and C is the channel dimension\n",
        "          \n",
        "        Return:\n",
        "        - y: Tensor of the shape BxLxC\n",
        "        \"\"\"\n",
        "        \n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Process the input.                                                #\n",
        "        ###########################################################################\n",
        "\n",
        "        x = self.Lin1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        y = self.Lin2(x)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1671c24f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1671c24f",
        "outputId": "1b8c753e-facf-455b-d67c-c80be9881560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 8])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "ff_dim = 4\n",
        "model = FeedForwardNetwork(8, ff_dim, 0.1)\n",
        "y = model(x)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa64217",
      "metadata": {
        "id": "daa64217"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.3: Implement a Single Transformer Encoder Cell (8 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c5aca2a1",
      "metadata": {
        "id": "c5aca2a1"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderCell(nn.Module):\n",
        "    \"\"\"\n",
        "    A single cell (unit) for the Transformer encoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension for each token in a sequence\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - ff_dim: The hidden dimension for a feedforward network\n",
        "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
        "          modules.\n",
        "        \"\"\"\n",
        "        super(TransformerEncoderCell, self).__init__()\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: A single Transformer encoder cell consists of \n",
        "        # 1. A multi-head attention module\n",
        "        # 2. Followed by dropout\n",
        "        # 3. Followed by layer norm (check nn.LayerNorm)\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#torch.nn.LayerNorm\n",
        "        #                                                                         #\n",
        "        # At the same time, it also has\n",
        "        # 1. A feedforward network\n",
        "        # 2. Followed by dropout\n",
        "        # 3. Followed by layer norm\n",
        "        ###########################################################################\n",
        "\n",
        "        # 1st module\n",
        "        self.multiHeadAttention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.layerNorm1 = nn.LayerNorm(input_dim)\n",
        "        # 2nd module\n",
        "        self.feedForward = FeedForwardNetwork(input_dim, ff_dim, dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layerNorm2 = nn.LayerNorm(input_dim)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - mask: Tensor for multi-head attention\n",
        "        \"\"\"\n",
        "        \n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Get the output of the multi-head attention part (with dropout     #\n",
        "        # and layer norm), which is used as input to the feedforward network (    #\n",
        "        # again, followed by dropout and layer norm).                             #\n",
        "        #                                                                         #\n",
        "        # Don't forget the residual connections for both parts.                   #\n",
        "        ###########################################################################\n",
        "\n",
        "        # 1st module/block\n",
        "        # multi head attention output with dropout\n",
        "        halfOut = self.dropout1(self.multiHeadAttention(x,x,x,mask))\n",
        "        # add residual & norm\n",
        "        normOut = self.layerNorm1(halfOut + x)\n",
        "\n",
        "        # 2nd module/block\n",
        "        # feed forward\n",
        "        FFOut = self.dropout2(self.feedForward(normOut))\n",
        "        # add residual & norm\n",
        "        y = self.layerNorm2(FFOut + normOut)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "77e4fcff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77e4fcff",
        "outputId": "faec9142-4497-46a2-efce-5f14d7942413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 8])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "mask = torch.randn((2, 10)) > 0.5\n",
        "mask = mask.unsqueeze(1).unsqueeze(-1)\n",
        "num_heads = 4\n",
        "model = TransformerEncoderCell(8, num_heads, 32, 0.1)\n",
        "y = model(x, mask)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0944cd8",
      "metadata": {
        "id": "b0944cd8"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.4: Implement Transformer Encoder (5 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f72b398a",
      "metadata": {
        "id": "f72b398a"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A full encoder consisting of a set of TransformerEncoderCell.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension for each token in a sequence\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - ff_dim: The hidden dimension for a feedforward network\n",
        "        - num_cells: Number of TransformerEncoderCells\n",
        "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
        "          modules.\n",
        "        \"\"\"\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        \n",
        "        self.norm = None\n",
        "        ###########################################################################\n",
        "        # TODO: Construct a nn.ModuleList to store a stack of                     #\n",
        "        # TranformerEncoderCells. Check the documentation here of how to use it   #\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList\n",
        "        \n",
        "        # At the same time, define a layer normalization layer to process the     #\n",
        "        # output of the entire encoder.                                           #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # initialize module list\n",
        "        self.moduleList = nn.ModuleList()\n",
        "        # add desired number of TransformerEncoderCells\n",
        "        for cell in range(num_cells):\n",
        "          self.moduleList.append(TransformerEncoderCell(input_dim, num_heads, ff_dim, dropout))\n",
        "        # norm layer\n",
        "        self.norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "        - mask: Tensor for multi-head attention\n",
        "        \n",
        "        Return:\n",
        "        - y: Tensor of the shape of BxLxC, which is the normalized output of the encoder\n",
        "        \"\"\"\n",
        "        \n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Feed x into the stack of TransformerEncoderCells and then         #\n",
        "        # normalize the output with layer norm.                                   #\n",
        "        ###########################################################################\n",
        "\n",
        "        # feeding x through each cell \n",
        "        for module in self.moduleList:\n",
        "          x = module(x,mask)\n",
        "        \n",
        "        # normalize\n",
        "        y = self.norm(x)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return y\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "64ddad9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ddad9c",
        "outputId": "ccefa96c-ebbb-4cb3-a678-7590603d9956"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 10, 8])\n"
          ]
        }
      ],
      "source": [
        "x = torch.randn((2, 10, 8))\n",
        "mask = torch.randn((2, 10)) > 0.5\n",
        "mask = mask.unsqueeze(1).unsqueeze(-1)\n",
        "num_heads = 4\n",
        "model = TransformerEncoder(8, num_heads, 32, 2, 0.1)\n",
        "y = model(x)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4c4330c",
      "metadata": {
        "id": "b4c4330c"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.5: Implement Positional Encoding (7 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "52b5ff70",
      "metadata": {
        "id": "52b5ff70"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    A module that adds positional encoding to each of the token's features.\n",
        "    So that the Transformer is position aware.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, max_len: int=10000):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension about the features for each token\n",
        "        - max_len: The maximum sequence length\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Compute the positional encoding and add it to x.\n",
        "        \n",
        "        Input:\n",
        "        - x: Tensor of the shape BxLxC, where B is the batch size, L is the sequence length,\n",
        "          and C is the channel dimension\n",
        "          \n",
        "        Return:\n",
        "        - x: Tensor of the shape BxLxC, with the positional encoding added to the input\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "        input_dim = x.shape[2]\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Compute the positional encoding                                   #\n",
        "        # Check Section 3.5 for the definition (https://arxiv.org/pdf/1706.03762.pdf)\n",
        "        #                                                                         #\n",
        "        # It's a bit messy, but the definition is provided for your here for your #\n",
        "        # convenience (in LaTex).                                                 #\n",
        "        # PE_{(pos,2i)} = sin(pos / 10000^{2i/\\dmodel})                           #\n",
        "        # PE_{(pos,2i+1)} = cos(pos / 10000^{2i/\\dmodel})                         #\n",
        "        #                                                                         #\n",
        "        # You should replace 10000 with max_len here.\n",
        "        ###########################################################################\n",
        "\n",
        "        # tensor to hold positional encoding values, BxLxC\n",
        "        pe = torch.zeros(x.shape[0], seq_len, input_dim)\n",
        "        \n",
        "        # double for loop logic\n",
        "        # for pos in range(seq_len):\n",
        "        #   for i in range(input_dim):\n",
        "        #     if i % 2 != 0:\n",
        "        #         pe[:, pos, i] = torch.cos(torch.tensor(pos) / self.max_len ** (i / self.input_dim)).float()\n",
        "        #     else:\n",
        "        #         pe[:, pos, i] = torch.sin(torch.tensor(pos) / self.max_len ** (i / self.input_dim)).float()\n",
        "\n",
        "        posVect = torch.arange(seq_len)\n",
        "        for i in range(input_dim):\n",
        "          if i % 2 != 0:\n",
        "            pe[:,:,i] = torch.cos(posVect * (self.max_len ** (-i / self.input_dim)))\n",
        "          else:\n",
        "            pe[:,:,i] = torch.sin(posVect * (self.max_len ** (-i / self.input_dim)))\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        x = x + pe.to(x.device)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "6d1d76c1",
      "metadata": {
        "id": "6d1d76c1"
      },
      "outputs": [],
      "source": [
        "# Sanity check\n",
        "x = torch.randn(1, 100, 20)\n",
        "pe = PositionalEncoding(20)\n",
        "y = pe(x)\n",
        "assert len(x.shape) == len(y.shape)\n",
        "for dim_x, dim_y in zip(x.shape, y.shape):\n",
        "    assert dim_x == dim_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5a34a7de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "5a34a7de",
        "outputId": "0a8da0bf-a970-4520-d1f9-be4d8b99af20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdc0dd80d30>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "pe = PositionalEncoding(20)\n",
        "y = pe.forward((torch.zeros(5, 100, 20)))\n",
        "plt.plot(np.arange(100), y[0, :, 4:8].data.numpy())\n",
        "plt.legend([\"dim %d\"%p for p in [4,5,6,7]])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "403b5eb6",
      "metadata": {
        "id": "403b5eb6"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.6: Implement a Transformer-based Text Classifier (5 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ea75af7f",
      "metadata": {
        "id": "ea75af7f"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    A Transformer-based text classifier.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "            vocab_size: int, embed_dim: int, num_heads: int, trx_ff_dim: int, \n",
        "            num_trx_cells: int, num_class: int, dropout: float=0.1, pad_token: int=0\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - vocab_size: Vocabulary size, indicating how many tokens we have in total.\n",
        "        - embed_dim: The dimension of word embeddings\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - trx_ff_dim: The hidden dimension for a feedforward network\n",
        "        - num_trx_cells: Number of TransformerEncoderCells\n",
        "        - dropout: Dropout ratio\n",
        "        - pad_token: The index of the padding token.\n",
        "        \"\"\"\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        # word embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_token)\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define a module for positional encoding, Transformer encoder, and #\n",
        "        # a output layer                                                          #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # positional encoding\n",
        "        self.pos = PositionalEncoding(embed_dim)\n",
        "        # encoder\n",
        "        self.encoder = TransformerEncoder(embed_dim, num_heads, trx_ff_dim, num_trx_cells, dropout)\n",
        "        # linear output layer\n",
        "        self.lin = nn.Linear(embed_dim, num_class)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "    def forward(self, text, mask=None):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - text: Tensor with the shape of BxLxC.\n",
        "        - mask: Tensor for multi-head attention\n",
        "        \n",
        "        Return:\n",
        "        - logits: Tensor with the shape of BxK, where K is the number of classes\n",
        "        \"\"\"\n",
        "        \n",
        "        # word embeddings, note we multiple the embeddings by a factor\n",
        "        embedded = self.embedding(text) * math.sqrt(self.embed_dim)\n",
        "        \n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: Apply positional embedding to the input, which is then fed into   #\n",
        "        # the encoder. Average pooling is applied then to all the features of all #\n",
        "        # tokens. Finally, the logits are computed based on the pooled features.  #\n",
        "        ###########################################################################\n",
        "\n",
        "        # add pos embedding into the word embedding\n",
        "        posEmbedded = self.pos(embedded)\n",
        "        # send through encoder module\n",
        "        encodedWords = self.encoder(posEmbedded)\n",
        "        # average pooling the feature\n",
        "        avgPooledWords = torch.mean(encodedWords, dim=1)\n",
        "        # computing logits\n",
        "        logits = self.lin(avgPooledWords)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5e926e90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e926e90",
        "outputId": "f9e1639f-0c66-4873-d724-6b7abe58bc62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: torch.Size([2, 10]), mask: torch.Size([2, 1, 1, 10])\n",
            "torch.Size([2, 3])\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 10\n",
        "embed_dim = 16\n",
        "num_heads = 4\n",
        "trx_ff_dim = 16\n",
        "num_trx_cells = 2\n",
        "num_class = 3\n",
        "\n",
        "x = torch.arange(vocab_size).view(1, -1)\n",
        "x = torch.cat((x, x), dim=0)\n",
        "mask = (x != 0).unsqueeze(-2).unsqueeze(1)\n",
        "model = TransformerClassifier(vocab_size, embed_dim, num_heads, trx_ff_dim, num_trx_cells, num_class)\n",
        "print('x: {}, mask: {}'.format(x.shape, mask.shape))\n",
        "y = model(x, mask)\n",
        "assert len(y.shape) == 2 and y.shape[0] == x.shape[0] and y.shape[1] == num_class\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c1f02fc",
      "metadata": {
        "id": "8c1f02fc"
      },
      "source": [
        "### <font size='4' color='red'>Task 2.7: Define the Model and Loss Function (3 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "46bd5779",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46bd5779",
        "outputId": "faa35c97-bd19-40f4-9a6d-91e09a8b2446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 1782 batches | accuracy    0.645\n",
            "| epoch   1 |  1000/ 1782 batches | accuracy    0.784\n",
            "| epoch   1 |  1500/ 1782 batches | accuracy    0.827\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 40.22s | valid accuracy    0.846 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 1782 batches | accuracy    0.869\n",
            "| epoch   2 |  1000/ 1782 batches | accuracy    0.871\n",
            "| epoch   2 |  1500/ 1782 batches | accuracy    0.879\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 39.26s | valid accuracy    0.875 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 1782 batches | accuracy    0.900\n",
            "| epoch   3 |  1000/ 1782 batches | accuracy    0.900\n",
            "| epoch   3 |  1500/ 1782 batches | accuracy    0.899\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 39.82s | valid accuracy    0.887 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 1782 batches | accuracy    0.917\n",
            "| epoch   4 |  1000/ 1782 batches | accuracy    0.914\n",
            "| epoch   4 |  1500/ 1782 batches | accuracy    0.914\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 39.94s | valid accuracy    0.886 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 1782 batches | accuracy    0.930\n",
            "| epoch   5 |  1000/ 1782 batches | accuracy    0.928\n",
            "| epoch   5 |  1500/ 1782 batches | accuracy    0.929\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 39.86s | valid accuracy    0.902 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "assert torch.cuda.is_available()\n",
        "# device = 'cuda'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 5 # epoch\n",
        "lr = 0.0005  # learning rate\n",
        "batch_size = 64 # batch size for training\n",
        "  \n",
        "train_iter = AG_NEWS(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "\n",
        "num_heads = 4\n",
        "num_trx_cells = 2\n",
        "\n",
        "gradient_norm_clip = 1\n",
        "\n",
        "# adding a hidden dim variable\n",
        "hid_dim = 256\n",
        "\n",
        "###########################################################################\n",
        "# Define a Transformer-based text classifier and a loss function.         #\n",
        "###########################################################################\n",
        "\n",
        "model = TransformerClassifier(vocab_size, emsize, num_heads, hid_dim, num_trx_cells, num_class)\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 1e-8)\n",
        "total_accu = None\n",
        "\n",
        "# You should be able to get a validation accuracy around 89%\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, train_dataloader, loss_func, device, gradient_norm_clip)\n",
        "    accu_val = evaluate(model, valid_dataloader, loss_func, device)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fba2a914",
      "metadata": {
        "id": "fba2a914"
      },
      "source": [
        "## Part 3: Image Classification with Transformer (10 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d670e6",
      "metadata": {
        "id": "b8d670e6"
      },
      "source": [
        "### <font size='4' color='red'>Task 3.1: Implement VisionTransformer for Image Classification (no flor loops are allowed, 7 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "87161192",
      "metadata": {
        "id": "87161192"
      },
      "outputs": [],
      "source": [
        "class VisionTransformerClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    In the model, we partition an image into non-overlapping patches. Each patch is treated as a token.\n",
        "    We can get a sequence of such tokens by flattening the patches. Each token's embeddings is the\n",
        "    flattened RGB pixel values. If the patch size is 4, then the embeddings' dimension is 4*4*3.\n",
        "    You can check this paper https://arxiv.org/pdf/2010.11929.pdf for reference.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "            patch_size: int, num_heads: int, trx_ff_dim: int, \n",
        "            num_trx_cells: int, num_class: int, dropout: float=0.1\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - patch_size: Size of the non-overlapping patches\n",
        "        - num_heads: Number of attention heads\n",
        "        - trx_ff_dim: Hidden dimension of the feedforward network in a Transformer encoder\n",
        "        - num_trx_cells: Number of TransformerEncoderCells \n",
        "        - num_class: Number of image classes\n",
        "        - dropout: Dropout ratio\n",
        "        \"\"\"\n",
        "        super(VisionTransformerClassifier, self).__init__()\n",
        "        \n",
        "        self.patch_size = patch_size\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define a TransformerEncoder that takens non-overlapping patches   #\n",
        "        # of an image as input and another output layer for classification.       #\n",
        "        #                                                                         #\n",
        "        # Intuitively, we need 2D positional encodings for each patch according to#\n",
        "        # its x and y coordinates. But this reference paper https://arxiv.org/pdf/2010.11929.pdf\n",
        "        # shows there is no significance difference on accuracies. It is bit      #\n",
        "        # weird. But you can simply use the 1D positional encoding you have       #\n",
        "        # implemented earlier. You can experiment with 2D positional encodings    #\n",
        "        # if you like to earn extra credits.                                      #\n",
        "        ###########################################################################\n",
        "        self.channels = 3 #since RGB\n",
        "        self.embed_dim = self.patch_size * self.patch_size * self.channels\n",
        "\n",
        "        self.encoder = TransformerEncoder(self.embed_dim, num_heads, trx_ff_dim, num_trx_cells, dropout)\n",
        "        self.lin = nn.Linear(self.embed_dim, num_class)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "\n",
        "        # def init_weights(self):\n",
        "        #   initrange = 0.5\n",
        "        #   self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        #   self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        #   self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, image: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "        - image: Tensor of the shape BxCxHxW, where H and W are the height and width, respectively.\n",
        "        \n",
        "        Return:\n",
        "        - logtis: Classification logits\n",
        "        \"\"\"\n",
        "        \n",
        "        b, c, h, w = image.shape\n",
        "\n",
        "        ###########################################################################\n",
        "        # TODO: Partition an image into non-overlapping patches. Think of how to  #\n",
        "        # reshape the tensor to convert it to be the BxLxC format, which we have  #\n",
        "        # extensively used for NLP tasks. You may find tensor.permute helpful.    #\n",
        "        # Check documentation here https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute\n",
        "        ###########################################################################\n",
        "        # unfold dimension 2 (height) with size patch_size and step patch_size so it doesn't overlap\n",
        "        patchTensor = image.unfold(2, self.patch_size, self.patch_size)\n",
        "        # unfold along width dim 3\n",
        "        patchTensor = patchTensor.unfold(3, self.patch_size, self.patch_size)\n",
        "        # change dimension to BxCxPatch_sizexPatch_sizexH'xW')\n",
        "        patchTensor = patchTensor.permute(0,1,4,5,2,3)\n",
        "        # reshape to BxCxL\n",
        "        L = (h // self.patch_size) * (w // self.patch_size)\n",
        "        patchTensor = patchTensor.reshape(b,L,-1)\n",
        "        #print(patchTensor.shape)\n",
        "        # send the processed input into the module\n",
        "        patchEncoded = self.encoder(patchTensor)\n",
        "        #print(patchEncoded.shape)\n",
        "        # global avg pool as used in the paper\n",
        "        avgPooledWords = torch.mean(patchEncoded, dim=1)\n",
        "        # compute logits\n",
        "        logits = self.lin(avgPooledWords)\n",
        "        #print(logits.shape)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1c0a5642",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c0a5642",
        "outputId": "2db8f247-87dd-4be7-c12e-7fb1e6da3ae3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 5])\n"
          ]
        }
      ],
      "source": [
        "# Sanity check\n",
        "image = torch.randn((2, 3, 32, 32))\n",
        "patch_size = 4\n",
        "num_heads = 4\n",
        "num_trx_cells = 2\n",
        "trx_ff_dim = 16\n",
        "dropout = 0.1\n",
        "num_class = 5\n",
        "\n",
        "vit = VisionTransformerClassifier(patch_size, num_heads, trx_ff_dim, num_trx_cells, num_class, dropout)\n",
        "logits = vit(image)\n",
        "assert len(logits.shape) == 2 and logits.shape[0] == image.shape[0] and logits.shape[1] == num_class\n",
        "print(logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "966276ca",
      "metadata": {
        "id": "966276ca"
      },
      "source": [
        "### Prepare Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b80c3d63",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b80c3d63",
        "outputId": "317c83ba-62a6-4da0-e5d9-50ebd0bbea65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '../datasets'\n",
            "/content\n",
            "--2023-04-11 04:53:01--  http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  14.4MB/s    in 8.3s    \n",
            "\n",
            "2023-04-11 04:53:11 (19.7 MB/s) - ‘cifar-10-python.tar.gz’ saved [170498071/170498071]\n",
            "\n",
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ],
      "source": [
        "# let's download the data\n",
        "%cd ../datasets\n",
        "\n",
        "# 1 -- Linux \n",
        "# 2 -- MacOS\n",
        "# 3 -- Command Prompt on Windows\n",
        "# 4 -- manually downloading the data\n",
        "choice = 1\n",
        "\n",
        "\n",
        "if choice == 1:\n",
        "    # should work well on Linux and in Powershell on Windows\n",
        "    !wget http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
        "elif choice == 2 or choice ==3:\n",
        "    # if wget is not available for you, try curl\n",
        "    # should work well on MacOS\n",
        "    !curl http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz --output cifar-10-python.tar.gz\n",
        "else:\n",
        "    print('Please manually download the data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz and put it under the datasets folder.')\n",
        "!tar -xzvf cifar-10-python.tar.gz\n",
        "\n",
        "if choice==3:\n",
        "    !del cifar-10-python.tar.gz\n",
        "else:\n",
        "    !rm cifar-10-python.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "724c00ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "724c00ec",
        "outputId": "b3222557-bf14-4a7a-bdc2-d8ac19a1765d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('X_train: ', (49000, 3, 32, 32))\n",
            "('y_train: ', (49000,))\n",
            "('X_val: ', (1000, 3, 32, 32))\n",
            "('y_val: ', (1000,))\n",
            "('X_test: ', (1000, 3, 32, 32))\n",
            "('y_test: ', (1000,))\n"
          ]
        }
      ],
      "source": [
        "from six.moves import cPickle as pickle\n",
        "import numpy as np\n",
        "import os\n",
        "from imageio import imread\n",
        "import platform\n",
        "\n",
        "def load_pickle(f):\n",
        "    version = platform.python_version_tuple()\n",
        "    if version[0] == '2':\n",
        "        return  pickle.load(f)\n",
        "    elif version[0] == '3':\n",
        "        return  pickle.load(f, encoding='latin1')\n",
        "    raise ValueError(\"invalid python version: {}\".format(version))\n",
        "\n",
        "def load_CIFAR_batch(filename):\n",
        "  \"\"\" load single batch of cifar \"\"\"\n",
        "  with open(filename, 'rb') as f:\n",
        "    datadict = load_pickle(f)\n",
        "    X = datadict['data']\n",
        "    Y = datadict['labels']\n",
        "    X = X.reshape(10000, 3, 32, 32).transpose(0,2,3,1).astype(\"float\")\n",
        "    Y = np.array(Y)\n",
        "    return X, Y\n",
        "\n",
        "def load_CIFAR10(ROOT):\n",
        "  \"\"\" load all of cifar \"\"\"\n",
        "  xs = []\n",
        "  ys = []\n",
        "  for b in range(1,6):\n",
        "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
        "    X, Y = load_CIFAR_batch(f)\n",
        "    xs.append(X)\n",
        "    ys.append(Y)\n",
        "  Xtr = np.concatenate(xs)\n",
        "  Ytr = np.concatenate(ys)\n",
        "  del X, Y\n",
        "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
        "  return Xtr, Ytr, Xte, Yte\n",
        "\n",
        "\n",
        "def get_CIFAR10_data(cifar10_dir, num_training=49000, num_validation=1000, num_test=1000,\n",
        "                     subtract_mean=True):\n",
        "    \"\"\"\n",
        "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
        "    it for classifiers. These are the same steps as we used for the SVM, but\n",
        "    condensed to a single function.\n",
        "    \"\"\"\n",
        "    # Load the raw CIFAR-10 data\n",
        "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
        "\n",
        "    # Subsample the data\n",
        "    mask = list(range(num_training, num_training + num_validation))\n",
        "    X_val = X_train[mask]\n",
        "    y_val = y_train[mask]\n",
        "    mask = list(range(num_training))\n",
        "    X_train = X_train[mask]\n",
        "    y_train = y_train[mask]\n",
        "    mask = list(range(num_test))\n",
        "    X_test = X_test[mask]\n",
        "    y_test = y_test[mask]\n",
        "\n",
        "    # Normalize the data: subtract the mean image\n",
        "    if subtract_mean:\n",
        "      mean_image = np.mean(X_train, axis=0)\n",
        "      X_train -= mean_image\n",
        "      X_val -= mean_image\n",
        "      X_test -= mean_image\n",
        "\n",
        "    # Transpose so that channels come first\n",
        "    X_train = X_train.transpose(0, 3, 1, 2).copy()\n",
        "    X_val = X_val.transpose(0, 3, 1, 2).copy()\n",
        "    X_test = X_test.transpose(0, 3, 1, 2).copy()\n",
        "\n",
        "    # Package data into a dictionary\n",
        "    return {\n",
        "      'X_train': X_train, 'y_train': y_train,\n",
        "      'X_val': X_val, 'y_val': y_val,\n",
        "      'X_test': X_test, 'y_test': y_test,\n",
        "    }\n",
        "\n",
        "# Split the data into train, val, and test sets. \n",
        "# Check the get_CIFAR10_data function for more details\n",
        "cifar10_dir = 'cifar-10-batches-py'\n",
        "data = get_CIFAR10_data(cifar10_dir)\n",
        "for k, v in list(data.items()):\n",
        "    print(('%s: ' % k, v.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f770e8d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f770e8d3",
        "outputId": "cd481c33-1bb5-4fd3-e13c-3f87fad4c038"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 32, 32]) tensor([1, 7, 1, 5, 1, 5, 5, 0])\n",
            "torch.Size([8, 3, 32, 32]) tensor([1, 3, 3, 7, 6, 7, 5, 3])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data.dataset import TensorDataset\n",
        "\n",
        "def make_dataloader(x, y, batch_size, is_train):\n",
        "    dataset = TensorDataset(\n",
        "        torch.from_numpy(y).long(),\n",
        "        torch.from_numpy(x).float() \n",
        "    )\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=is_train,\n",
        "        num_workers=2,\n",
        "        drop_last=is_train\n",
        "    )\n",
        "    return dataloader\n",
        "    \n",
        "train_loader = make_dataloader(data['X_train'], data['y_train'], 8, True)\n",
        "for idx, (lab, im) in enumerate(train_loader):\n",
        "    if idx > 1:\n",
        "        break\n",
        "    print(im.shape, lab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "570d32af",
      "metadata": {
        "id": "570d32af"
      },
      "source": [
        "### <font size='4' color='red'>Task 3.2: Define the Model and Loss Function (3 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "81f44a98",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81f44a98",
        "outputId": "478e222e-5c41-44e7-c6de-13579db9eaf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| epoch   1 |   500/ 3062 batches | accuracy    0.205\n",
            "| epoch   1 |  1000/ 3062 batches | accuracy    0.257\n",
            "| epoch   1 |  1500/ 3062 batches | accuracy    0.276\n",
            "| epoch   1 |  2000/ 3062 batches | accuracy    0.290\n",
            "| epoch   1 |  2500/ 3062 batches | accuracy    0.308\n",
            "| epoch   1 |  3000/ 3062 batches | accuracy    0.311\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 33.44s | valid accuracy    0.315 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 3062 batches | accuracy    0.323\n",
            "| epoch   2 |  1000/ 3062 batches | accuracy    0.325\n",
            "| epoch   2 |  1500/ 3062 batches | accuracy    0.344\n",
            "| epoch   2 |  2000/ 3062 batches | accuracy    0.337\n",
            "| epoch   2 |  2500/ 3062 batches | accuracy    0.339\n",
            "| epoch   2 |  3000/ 3062 batches | accuracy    0.345\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 32.11s | valid accuracy    0.366 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 3062 batches | accuracy    0.358\n",
            "| epoch   3 |  1000/ 3062 batches | accuracy    0.346\n",
            "| epoch   3 |  1500/ 3062 batches | accuracy    0.363\n",
            "| epoch   3 |  2000/ 3062 batches | accuracy    0.370\n",
            "| epoch   3 |  2500/ 3062 batches | accuracy    0.375\n",
            "| epoch   3 |  3000/ 3062 batches | accuracy    0.376\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 32.11s | valid accuracy    0.391 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 3062 batches | accuracy    0.390\n",
            "| epoch   4 |  1000/ 3062 batches | accuracy    0.392\n",
            "| epoch   4 |  1500/ 3062 batches | accuracy    0.389\n",
            "| epoch   4 |  2000/ 3062 batches | accuracy    0.395\n",
            "| epoch   4 |  2500/ 3062 batches | accuracy    0.401\n",
            "| epoch   4 |  3000/ 3062 batches | accuracy    0.405\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 32.17s | valid accuracy    0.399 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 3062 batches | accuracy    0.413\n",
            "| epoch   5 |  1000/ 3062 batches | accuracy    0.416\n",
            "| epoch   5 |  1500/ 3062 batches | accuracy    0.415\n",
            "| epoch   5 |  2000/ 3062 batches | accuracy    0.411\n",
            "| epoch   5 |  2500/ 3062 batches | accuracy    0.421\n",
            "| epoch   5 |  3000/ 3062 batches | accuracy    0.431\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 33.26s | valid accuracy    0.458 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "patch_size = 4\n",
        "embed_dim = 128\n",
        "num_heads = 4\n",
        "trx_ff_dim = 128\n",
        "num_trx_cells = 2\n",
        "num_class = 10\n",
        "\n",
        "###########################################################################\n",
        "# TODO: Define the model and loss function\n",
        "###########################################################################\n",
        "\n",
        "model = VisionTransformerClassifier(patch_size, num_heads, trx_ff_dim, num_trx_cells, num_class)\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "model = model.to(device)\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = make_dataloader(data['X_train'], data['y_train'], batch_size, True)\n",
        "val_loader = make_dataloader(data['X_test'], data['y_test'], batch_size, False)\n",
        "\n",
        "# Hyperparameters\n",
        "epochs = 5 # epoch\n",
        "lr = 0.001\n",
        "gradient_norm_clips = 0.1\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, 1e-8)\n",
        "total_accu = None\n",
        "\n",
        "# You should be able to get an accuracy around 36%\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model, train_loader, loss_func, device, gradient_norm_clip)\n",
        "    accu_val = evaluate(model, val_loader, loss_func, device)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "        scheduler.step()\n",
        "    else:\n",
        "        total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e6ea7e",
      "metadata": {
        "id": "f0e6ea7e"
      },
      "source": [
        "## Part 4: Machine Translation with Transformer (25 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6ad5d07",
      "metadata": {
        "id": "e6ad5d07"
      },
      "source": [
        "### <font size='4' color='red'>Task 4.1: Implement Transformer Decoder Cell (10 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "32619440",
      "metadata": {
        "id": "32619440"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoderCell(nn.Module):\n",
        "    \"\"\"\n",
        "    A single cell (unit) of the Transformer decoder.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int, ff_dim: int, dropout: float=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension for each token in a sequence\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - ff_dim: The hidden dimension for a feedforward network\n",
        "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
        "          modules.\n",
        "        \"\"\"\n",
        "        super(TransformerDecoderCell, self).__init__()\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Similar to the TransformerEncoderCell, define two                 #\n",
        "        # MultiHeadAttention modules. One for processing the tokens on the        # \n",
        "        # decoder side. The other for getting the attention across the encoder.   #\n",
        "        # and the decoder. Also define a feedforward network. Don't forget the    #\n",
        "        # Dropout and Layer Norm layers.                                          #\n",
        "        ###########################################################################\n",
        "\n",
        "        # 1st multi-head attention \n",
        "        self.multiHead1 = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.layerNorm1 = nn.LayerNorm(input_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        # 2nd multi-head attention\n",
        "        self.multiHead2 = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.layerNorm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # feed forward\n",
        "        self.feedForward = nn.Sequential(nn.Linear(input_dim, ff_dim), nn.ReLU(), nn.Linear(ff_dim, input_dim))\n",
        "        self.layerNorm3 = nn.LayerNorm(input_dim)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, x: torch.Tensor, encoder_output: torch.Tensor, src_mask=None, tgt_mask=None):            \n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "        - x: Tensor of BxLdxC, word embeddings on the decoder side\n",
        "        - encoder_output: Tensor of BxLexC, word embeddings on the encoder side\n",
        "        - src_mask: Tensor, masks of the tokens on the encoder side\n",
        "        - tgt_mask: Tensor, masks of the tokens on the decoder side\n",
        "        \n",
        "        Return:\n",
        "        - y: Tensor of BxLdxC. Attended features for all tokens on the decoder side.\n",
        "        \"\"\"\n",
        "        \n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Compute the self-attended features for the tokens on the decoder  #\n",
        "        # side. Then compute the corss-attended features for the tokens on the    #\n",
        "        # decoder side to the encoded features, which are finally feed into the   #\n",
        "        # feedforward network                                                     #\n",
        "        ###########################################################################\n",
        "\n",
        "        # pass through first multi-head\n",
        "        selfAttendedFeatures = self.multiHead1(x,x,x,tgt_mask)\n",
        "        selfAFnorm = self.layerNorm1(selfAttendedFeatures + self.dropout1(selfAttendedFeatures))\n",
        "\n",
        "        # pass through 2nd multi-head, Query and Keys are encoder output duplicated\n",
        "        crossAttendedFeatures = self.multiHead2(selfAFnorm, encoder_output, encoder_output, src_mask)\n",
        "        crossAFnorm = self.layerNorm2(crossAttendedFeatures + self.dropout2(crossAttendedFeatures))\n",
        "\n",
        "        # pass through feed forward\n",
        "        FFout = self.feedForward(crossAFnorm)\n",
        "        y = self.layerNorm3(crossAFnorm + self.dropout3(FFout))\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f1fe2ae8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1fe2ae8",
        "outputId": "ee66df11-343b-4dc1-c293-6a1b6cfdeba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 10, 16])\n"
          ]
        }
      ],
      "source": [
        "dec_feats = torch.randn((3, 10, 16))\n",
        "dec_mask = torch.randn((3, 1, 10, 10)) > 0.5\n",
        "\n",
        "enc_feats = torch.randn((3, 12, 16))\n",
        "enc_mask = torch.randn((3, 1, 1, 12)) > 0.5\n",
        "\n",
        "model = TransformerDecoderCell(16, 2, 32, 0.1)\n",
        "z = model(dec_feats, enc_feats, enc_mask, dec_mask)\n",
        "assert len(z.shape) == len(dec_feats.shape)\n",
        "for dim_z, dim_x in zip(z.shape, dec_feats.shape):\n",
        "    assert dim_z == dim_x\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36259c71",
      "metadata": {
        "id": "36259c71"
      },
      "source": [
        "### <font size='4' color='red'>Task 4.2: Implement Transformer Decoder (5 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "db0a3d21",
      "metadata": {
        "id": "db0a3d21"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A TransformerDecoder is a stack of multiple TransformerDecoderCells and a Layer Norm.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout=0.1):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - input_dim: Input dimension for each token in a sequence\n",
        "        - num_heads: Number of attention heads in a multi-head attention module\n",
        "        - ff_dim: The hidden dimension for a feedforward network\n",
        "        - num_cells: How many TransformerDecoderCells in stack\n",
        "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
        "          modules.\n",
        "        \"\"\"\n",
        "        super(TransformerDecoder, self).__init__()\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Construct a nn.ModuleList to store a stack of                     #\n",
        "        # TranformerDecoderCells. Check the documentation here of how to use it   #\n",
        "        # https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList\n",
        "        \n",
        "        # At the same time, define a layer normalization layer to process the     #\n",
        "        # output of the entire encoder.                                           #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # initialize module list\n",
        "        self.moduleList = nn.ModuleList()\n",
        "        # add desired number of TransformerEncoderCells\n",
        "        for cell in range(num_cells):\n",
        "          self.moduleList.append(TransformerDecoderCell(input_dim, num_heads, ff_dim, dropout))\n",
        "        # norm layer\n",
        "        self.norm = nn.LayerNorm(input_dim)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "    \n",
        "    def forward(self, x: torch.Tensor, encoder_output: torch.Tensor, src_mask=None, tgt_mask=None):            \n",
        "        \"\"\"\n",
        "        Inputs: \n",
        "        - x: Tensor of BxLdxC, word embeddings on the decoder side\n",
        "        - encoder_output: Tensor of BxLexC, word embeddings on the encoder side\n",
        "        - src_mask: Tensor, masks of the tokens on the encoder side\n",
        "        - tgt_mask: Tensor, masks of the tokens on the decoder side\n",
        "        \n",
        "        Return:\n",
        "        - y: Tensor of BxLdxC. Attended features for all tokens on the decoder side.\n",
        "        \"\"\"\n",
        "        \n",
        "        y = None\n",
        "        ###########################################################################\n",
        "        # TODO: Feed x into the stack of TransformerDecoderCells and then         #\n",
        "        # normalize the output with layer norm.                                   #\n",
        "        ###########################################################################\n",
        "        \n",
        "        # feeding x through each cell \n",
        "        for module in self.moduleList:\n",
        "          x = module(x, encoder_output, src_mask, tgt_mask)\n",
        "        \n",
        "        # normalize\n",
        "        y = self.norm(x)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0af7e67d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0af7e67d",
        "outputId": "c7ff88e5-9db6-47e5-976d-93ea0216701a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 10, 16])\n"
          ]
        }
      ],
      "source": [
        "dec_feats = torch.randn((3, 10, 16))\n",
        "dec_mask = torch.randn((3, 1, 10, 10)) > 0.5\n",
        "\n",
        "enc_feats = torch.randn((3, 12, 16))\n",
        "enc_mask = torch.randn((3, 1, 1, 12)) > 0.5\n",
        "\n",
        "model = TransformerDecoder(16, 2, 32, 2, 0.1)\n",
        "z = model(dec_feats, enc_feats, enc_mask, dec_mask)\n",
        "assert len(z.shape) == len(dec_feats.shape)\n",
        "for dim_z, dim_x in zip(z.shape, dec_feats.shape):\n",
        "    assert dim_z == dim_x\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08f0615f",
      "metadata": {
        "id": "08f0615f"
      },
      "source": [
        "### <font size='4' color='red'>Task 4.3: Implement a Transformer-based Sequence-to-sequence model (7 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "cad7dabf",
      "metadata": {
        "id": "cad7dabf"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer-based sequence-to-sequence model.\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "            num_encoder_layers: int, num_decoder_layers: int, embed_dim: int,\n",
        "            num_heads: int, src_vocab_size: int, tgt_vocab_size: int,\n",
        "            trx_ff_dim: int = 512, dropout: float = 0.1, pad_token: int=0\n",
        "        ):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - num_encoder_layers: How many TransformerEncoderCell in stack\n",
        "        - num_decoder_layers: How many TransformerDecoderCell in stack\n",
        "        - embed_dim: Word embeddings dimension\n",
        "        - num_heads: Number of attention heads\n",
        "        - src_vocab_size: Number of tokens in the source language vocabulary\n",
        "        - tgt_vocab_size: Number of tokens in the target language vocabulary\n",
        "        - trx_ff_dim: Hidden dimension in the feedforward network\n",
        "        - dropout: Dropout ratio\n",
        "        \"\"\"\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        \n",
        "        self.embed_dim = embed_dim\n",
        "        \n",
        "        # Word embeddings for both the source and target languages\n",
        "        self.src_token_embed = nn.Embedding(src_vocab_size, embed_dim, padding_idx=pad_token)\n",
        "        self.tgt_token_embed = nn.Embedding(tgt_vocab_size, embed_dim, padding_idx=pad_token)\n",
        "        \n",
        "        ###########################################################################\n",
        "        # TODO: Define the positional encoding, encoder, decoder, and the output  #\n",
        "        # layer. Think of how many classes are in the output layer.               #\n",
        "        ###########################################################################\n",
        "\n",
        "        # positional encoding\n",
        "        self.positional_encoding = PositionalEncoding(embed_dim, dropout)\n",
        "        # encoder\n",
        "        self.encoder = TransformerEncoder(embed_dim, num_heads, trx_ff_dim, num_encoder_layers, dropout)\n",
        "        # decoder\n",
        "        self.decoder = TransformerDecoder(embed_dim, num_heads, trx_ff_dim, num_decoder_layers, dropout)\n",
        "        # output layer\n",
        "        self.lin = nn.Linear(embed_dim, tgt_vocab_size)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: torch.Tensor, tgt_mask: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - src: Tensor of BxLe, word indexes in the source language\n",
        "        - tgt: Tensor of BxLd, word indexes in the target language\n",
        "        - src_mask: Tensor, masks of the tokens on the encoder side\n",
        "        - tgt_mask: Tensor, masks of the tokens on the decoder side\n",
        "        \n",
        "        Return:\n",
        "        - y: Tensor of BxLdxK. K is the number of classes in the output.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Get word embeddings. Not they are scaled.\n",
        "        src_embed = self.src_token_embed(src) * math.sqrt(self.embed_dim)\n",
        "        tgt_embed = self.tgt_token_embed(tgt) * math.sqrt(self.embed_dim)\n",
        "        \n",
        "        logits = None\n",
        "        ###########################################################################\n",
        "        # TODO: Add positional encodings to the word embeddings. Feed them then   #\n",
        "        # to the encoder and decoder, respectively. Get the logits finally.       #\n",
        "        ###########################################################################\n",
        "\n",
        "        # Add positional encodings to the word embedding\n",
        "        SrcPosEmb = self.positional_encoding(src_embed)\n",
        "        TgtPosEmb = self.positional_encoding(tgt_embed)\n",
        "\n",
        "        # Feed them to the encoder and decor\n",
        "        SrcEncoded = self.encoder(src_embed, src_mask)\n",
        "        TgtDecoded = self.decoder(tgt_embed, SrcEncoded, src_mask, tgt_mask)\n",
        "\n",
        "        # Get the logits\n",
        "        logits = self.lin(TgtDecoded)\n",
        "\n",
        "        ###########################################################################\n",
        "        #                             END OF YOUR CODE                            #\n",
        "        ###########################################################################\n",
        "        \n",
        "        return logits\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "5ef6d873",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ef6d873",
        "outputId": "6c7fa247-94ce-4860-952b-b6636e239b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 12])\n"
          ]
        }
      ],
      "source": [
        "src_vocab_size = 10\n",
        "src = torch.arange(src_vocab_size).view(1, -1)\n",
        "src = torch.cat((src, src), dim=0)\n",
        "src_mask = torch.randn((2, 1, 1, src_vocab_size)) > 0.5\n",
        "\n",
        "tgt_vocab_size = 12\n",
        "tgt = torch.arange(tgt_vocab_size).view(1, -1)\n",
        "tgt = torch.cat((tgt, tgt), dim=0)\n",
        "tgt_mask = torch.randn((2, 1, tgt_vocab_size, tgt_vocab_size)) > 0.5\n",
        "\n",
        "model = Seq2SeqTransformer(2, 2, 16, 2, src_vocab_size, tgt_vocab_size, 32, 0.1, 0)\n",
        "z = model(src, tgt, src_mask, tgt_mask)\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "922361b2",
      "metadata": {
        "id": "922361b2"
      },
      "source": [
        "### Create Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "c9a73cc5",
      "metadata": {
        "id": "c9a73cc5"
      },
      "outputs": [],
      "source": [
        "def subsequent_mask(size):\n",
        "    \"Mask out subsequent positions.\"\n",
        "    attn_shape = (1, size, size)\n",
        "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
        "    return torch.from_numpy(subsequent_mask) == 0\n",
        "\n",
        "\n",
        "def create_mask(src, tgt, pad_token=0):\n",
        "    src_mask = (src != pad_token).unsqueeze(-2).unsqueeze(1)\n",
        "    \n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "    tgt_mask = (tgt != pad_token).unsqueeze(-2)\n",
        "    tgt_mask = tgt_mask & subsequent_mask(tgt.shape[1]).type_as(tgt_mask.data)\n",
        "\n",
        "    return src_mask, tgt_mask.unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ebd199b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "ebd199b2",
        "outputId": "1f0b28a3-b67a-48ab-cf61-8162cf79364b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 1, 10]) torch.Size([2, 1, 10, 10])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's visualize what the target mask looks like\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.imshow(subsequent_mask(20)[0].numpy())\n",
        "\n",
        "x = torch.arange(src_vocab_size).view(1, -1)\n",
        "x = torch.cat((x, x), dim=0)\n",
        "src_mask, tgt_mask = create_mask(x, x)\n",
        "print(src_mask.shape, tgt_mask.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd3815f",
      "metadata": {
        "id": "efd3815f"
      },
      "source": [
        "### Prepare Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "276afbc7",
      "metadata": {
        "id": "276afbc7"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import Multi30k\n",
        "from typing import Iterable, List\n",
        "\n",
        "\n",
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}\n",
        "\n",
        "\n",
        "# # Create source and target language tokenizer. Make sure to install the dependencies.\n",
        "# !pip install -U spacy\n",
        "# !python -m spacy download en_core_web_sm\n",
        "# !python -m spacy download de_core_news_sm\n",
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        " \n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Training data Iterator \n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # Create torchtext's Vocab object \n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set UNK_IDX as the default index. This index is returned when the token is not found. \n",
        "# If not set, it throws RuntimeError when the queried token is not found in the Vocabulary. \n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "e7ac308f",
      "metadata": {
        "id": "e7ac308f"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]), \n",
        "                      torch.tensor(token_ids), \n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# src and tgt language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(\n",
        "        token_transform[ln], #Tokenization\n",
        "        vocab_transform[ln], #Numericalization\n",
        "        tensor_transform # Add BOS/EOS and create tensor\n",
        "    )\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tesors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch.transpose(0, 1), tgt_batch.transpose(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "052976db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052976db",
        "outputId": "76433cf0-26a0-430b-838c-8c39708b3ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src: torch.Size([8, 18]), tgt: torch.Size([8, 17])\n",
            "src: torch.Size([8, 20]), tgt: torch.Size([8, 19])\n",
            "src: torch.Size([8, 18]), tgt: torch.Size([8, 19])\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "for idx, (src, tgt) in enumerate(train_dataloader):\n",
        "    if idx > 2:\n",
        "        break\n",
        "    print('src: {}, tgt: {}'.format(src.shape, tgt.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e9d060",
      "metadata": {
        "id": "76e9d060"
      },
      "source": [
        "### <font size='4' color='red'>Task 4.4: Define the Model and Loss Function (3 points)</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b1cfcf01",
      "metadata": {
        "id": "b1cfcf01"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMBED_SIZE = 512\n",
        "NUM_ATTN_HEADS = 8\n",
        "FF_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "###########################################################################\n",
        "# TODO: Define the model and loss function.                               #\n",
        "# Note that this time we will generate tokens, where some of them in the  #\n",
        "# training time are from paddings. We don't want to penalize the model    #\n",
        "# if the output at such positions are wrong. You can use the              #\n",
        "# `ignore_index` in a loss function to suppress loss computation if the   #\n",
        "# ground-truth label is equal to the given value. Check here for          #\n",
        "# more details https://pytorch.org/docs/stable/nn.html#loss-functions     #\n",
        "###########################################################################\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMBED_SIZE, NUM_ATTN_HEADS, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FF_DIM)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "###########################################################################\n",
        "#                             END OF YOUR CODE                            #\n",
        "###########################################################################\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "transformer = transformer.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), \n",
        "    lr=0.0001, \n",
        "    betas=(0.9, 0.98), \n",
        "    eps=1e-9\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14426704",
      "metadata": {
        "id": "14426704"
      },
      "source": [
        "### Model Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "47d0266e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47d0266e",
        "outputId": "5af5c25b-9a13-441d-f515-f46fb313ba98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1, Train loss: 5.929, Val loss: 5.043, Epoch time = 58.139s\n",
            "Epoch: 2, Train loss: 4.608, Val loss: 4.303, Epoch time = 58.564s\n",
            "Epoch: 3, Train loss: 4.116, Val loss: 4.028, Epoch time = 57.950s\n",
            "Epoch: 4, Train loss: 3.707, Val loss: 3.710, Epoch time = 58.090s\n",
            "Epoch: 5, Train loss: 3.381, Val loss: 3.563, Epoch time = 58.507s\n",
            "Epoch: 6, Train loss: 3.129, Val loss: 3.363, Epoch time = 57.952s\n",
            "Epoch: 7, Train loss: 2.738, Val loss: 3.074, Epoch time = 58.234s\n",
            "Epoch: 8, Train loss: 2.454, Val loss: 2.976, Epoch time = 58.183s\n",
            "Epoch: 9, Train loss: 2.271, Val loss: 2.925, Epoch time = 58.615s\n",
            "Epoch: 10, Train loss: 2.113, Val loss: 2.906, Epoch time = 58.549s\n"
          ]
        }
      ],
      "source": [
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    \n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    train_iter_list = list(train_iter)\n",
        "    train_dataloader = DataLoader(train_iter_list, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "    \n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        src_mask, tgt_mask = create_mask(src, tgt_input)\n",
        "        src_mask = src_mask.to(device)\n",
        "        tgt_mask = tgt_mask.to(device)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[:, 1:]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(train_dataloader)\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_iter_list = list(val_iter)\n",
        "    val_dataloader = DataLoader(val_iter_list, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        tgt_input = tgt[:, :-1]\n",
        "\n",
        "        src_mask, tgt_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask)\n",
        "        \n",
        "        tgt_out = tgt[:, 1:]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(val_dataloader)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# You should be able to get train loss around 1.5 and val loss around 2.2\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "3660291b",
      "metadata": {
        "id": "3660291b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
